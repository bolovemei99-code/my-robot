# MCP Bot Deployment Guide

## ğŸ“‹ Project Structure
```
my-robot/
â”œâ”€â”€ main.py              # Bot application with /mcp command
â”œâ”€â”€ mcp.json            # MCP server configuration
â”œâ”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ Procfile           # Railway deployment config
â””â”€â”€ .gitignore         # Excluded files
```

## ğŸš€ Railway Deployment Steps

### 1. Push to GitHub
```bash
git add .
git commit -m "Add MCP configuration"
git push origin main
```

### 2. Deploy to Railway
1. Go to https://railway.app
2. Click "New Project" â†’ "Deploy from GitHub repo"
3. Select `my-robot` repository
4. Railway will auto-detect the Procfile

### 3. Set Environment Variables
In Railway Dashboard â†’ Settings â†’ Variables, add:

| Key | Value | Required |
|-----|-------|----------|
| `TG_TOKEN` | Your Telegram Bot Token | âœ… Yes |
| `XAI_API_KEY` | xAI API Key (for Grok) | âšª Optional |
| `OPENAI_API_KEY` | OpenAI API Key | âšª Optional |

### 4. Generate Domain
1. Go to Settings â†’ Networking
2. Click "Generate Domain"
3. Copy the generated URL (e.g., `your-bot.up.railway.app`)

### 5. Set Telegram Webhook
```bash
curl -X POST "https://api.telegram.org/bot<YOUR_TOKEN>/setWebhook?url=https://your-bot.up.railway.app/webhook"
```

Replace `<YOUR_TOKEN>` with your actual Telegram bot token.

## ğŸ§ª Testing

### Test Commands
1. Private message your bot:
   ```
   /help
   ```
   Should show: "ğŸ‰ å‘½ä»¤: /mcp ä½ å¥½ (AIå¯¹è¯) /add 10 åˆé¥­..."

2. Test MCP AI chat:
   ```
   /mcp ä½ å¥½
   ```
   Should reply with AI response

3. Test other features:
   ```
   /add 10 åˆé¥­
   /balance
   ```

## ğŸ”§ MCP Configuration

### Supported Models (mcp.json)
1. **local-llm** - Llama3 via Ollama
   - Requires Ollama running on localhost:11434
   - Uses MCP server with Python

2. **grok-api** - xAI Grok
   - Requires XAI_API_KEY environment variable
   - API: https://api.x.ai/v1/chat/completions

3. **openai-proxy** - OpenAI GPT
   - Requires OPENAI_API_KEY environment variable
   - API: https://api.openai.com/v1/chat/completions

## ğŸ“Š Architecture

```
Telegram User
    â†“
Telegram API (webhook)
    â†“
Railway (Flask app on port 8080)
    â†“
/mcp command handler
    â†“
MCP Server (localhost:8000)
    â†“
AI Model (Llama3/Grok/OpenAI)
```

## ğŸ› ï¸ Troubleshooting

### Bot not responding
- Check Railway logs for errors
- Verify TG_TOKEN is set correctly
- Confirm webhook is set: `curl https://api.telegram.org/bot<TOKEN>/getWebhookInfo`

### MCP errors
- Ensure mcp-server is running (Railway Procfile handles this)
- Check if localhost:8000 is accessible
- Verify API keys for external models

### Deployment fails
- Check requirements.txt has all dependencies
- Verify Procfile syntax is correct
- Check Railway build logs

## ğŸ“ Key Changes from Original

1. âœ… Fixed JSON syntax in mcp.json (quotes and spelling)
2. âœ… Changed TOKEN from hardcoded to environment variable
3. âœ… Added Flask app.run() for proper server startup
4. âœ… Added /mcp command handler for AI chat
5. âœ… Updated requirements.txt with Flask, mcp-server, requests

## ğŸ‰ Success Criteria

When deployment is successful, you should:
- âœ… See "MCP Bot å¯åŠ¨ï¼" in Railway logs
- âœ… Receive responses from `/help` command
- âœ… Get AI responses from `/mcp ä½ å¥½` command
- âœ… Have 2 processes running in Railway (web + mcp)

---

**Need help?** Check Railway logs or Telegram bot responses for error messages.
